{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3784ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from numba import jit\n",
    "import torch\n",
    "from scipy.spatial import distance_matrix\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509256c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6daa3790",
   "metadata": {},
   "source": [
    "\n",
    "Convert an arbitrary matrix into the weighted sum of distance matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaec23bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f0868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_stress(_model, tar_Wio):\n",
    "\n",
    "    _W_io = _model.forward()\n",
    "    loss_Wio = torch.sum(((_W_io-tar_Wio)**2)/_W_io.numel())\n",
    "    loss_W = loss_Wio\n",
    "\n",
    "    return loss_W\n",
    "\n",
    "\n",
    "def update_DyN(_model, _optim, tar_Wio, dyn_epochs, meanL_thres=0.01):\n",
    "    \n",
    "    max_loss, mean_loss = 0,0\n",
    "    for _ep in range(dyn_epochs):\n",
    "        loss_W = compute_stress(_model, tar_Wio)        \n",
    "        _optim.zero_grad()\n",
    "        loss_W.backward()\n",
    "        _optim.step()\n",
    "        if _ep%(dyn_epochs//10)==0:\n",
    "            mean_loss = round(torch.sum(torch.abs(_model.forward()-tar_Wio)).item()/tar_Wio.numel(),8) \n",
    "            max_loss = round(torch.max(torch.abs(_model.forward()-tar_Wio)).item(),8)\n",
    "            \n",
    "            # Print the current query loss\n",
    "            dyn_vecs = rand_vec@_model.forward(_prec=-1)\n",
    "            res_norms = torch.norm(tar_vecs-dyn_vecs, dim=1)\n",
    "            norm_loss = torch.sum(res_norms)/(dyn_vecs.shape[0]*dyn_vecs.shape[1])\n",
    "            print(norm_loss/torch.std(tar_vecs))\n",
    "            \n",
    "            print('---', _ep, '- DyN Loss:', loss_W.item(), '- Max Loss:', max_loss, '- Mean Loss:', mean_loss,'- Time:', datetime.now().time())\n",
    "        if mean_loss < meanL_thres: return _model, max_loss, mean_loss\n",
    "    \n",
    "    return _model, max_loss, mean_loss\n",
    "\n",
    "\n",
    "class dynMat(nn.Module):\n",
    "    def __init__(self, num_input, num_output, num_Qs, q_dim, p=1, _scale=5):\n",
    "        super(dynMat, self).__init__() \n",
    "\n",
    "        self.num_input = num_input\n",
    "        self.num_output = num_output\n",
    "        self.num_Qs = num_Qs\n",
    "        self.q_dim = q_dim\n",
    "        self.norm_p = p\n",
    "        self._scale = _scale\n",
    "        \n",
    "        # num_input = number of points Y\n",
    "        self.input_Qs = torch.nn.Parameter(1*torch.rand(num_Qs, num_input, q_dim, device=device))\n",
    "        \n",
    "        # num_output = number of points X\n",
    "        self.output_Qs = torch.nn.Parameter(1*torch.rand(num_Qs, num_output, q_dim, device=device))\n",
    "        \n",
    "        # num_Qs = H\n",
    "        self.lambdas_io = torch.nn.Parameter(torch.randn(num_Qs, 1, 1, device=device))\n",
    "        \n",
    "        \n",
    "    def forward(self, _prec=-1):\n",
    "        \n",
    "        if _prec != -1:\n",
    "            input_Qs = _prec*(torch.div(self.input_Qs, _prec, rounding_mode='floor'))\n",
    "            output_Qs = _prec*(torch.div(self.output_Qs, _prec, rounding_mode='floor'))\n",
    "        else:\n",
    "            input_Qs = self.input_Qs\n",
    "            output_Qs = self.output_Qs\n",
    "        \n",
    "        dist_io = self._scale*(torch.cdist(input_Qs, output_Qs, p=self.norm_p))         \n",
    "        W_io = torch.sum(dist_io*self.lambdas_io,0)\n",
    "        return W_io\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08678b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3595) tensor(12.7227)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Note that the matrix in this script is the transpose of the matrix in the paper.\n",
    "num_rowQ, num_colQ = 500,500\n",
    "tar_mat = torch.randn(num_rowQ, num_colQ, device=device)\n",
    "\n",
    "# \"z = Ay\" in paper is equivalent to \"z = y@tar_mat\" here.\n",
    "rand_vec = torch.rand(1000, num_rowQ, device=device)\n",
    "tar_vecs = rand_vec@tar_mat\n",
    "print(torch.mean(tar_vecs), torch.std(tar_vecs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e5517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meanL_thres = 1e-10\n",
    "max_dynEpoch = 50000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c599718",
   "metadata": {},
   "source": [
    "\n",
    "The parameters required to reconstruct a matrix of shape a*b is q_dim*H_num*(X_num+Y_num).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17891afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "{'H_num': 5, 'q_dim': 5, 'norm_p': 1, '_scale': 1}\n",
      "tensor(5.7826, grad_fn=<DivBackward0>)\n",
      "--- 0 - DyN Loss: 47.49249267578125 - Max Loss: 16.1501236 - Mean Loss: 6.5507715 - Time: 23:14:23.319784\n",
      "tensor(0.0963, grad_fn=<DivBackward0>)\n",
      "--- 5000 - DyN Loss: 1.960894227027893 - Max Loss: 6.60639238 - Mean Loss: 1.11402925 - Time: 23:19:48.717743\n",
      "tensor(0.0285, grad_fn=<DivBackward0>)\n",
      "--- 10000 - DyN Loss: 0.9692800045013428 - Max Loss: 4.73323345 - Mean Loss: 0.78511456 - Time: 23:25:20.959070\n",
      "tensor(0.0240, grad_fn=<DivBackward0>)\n",
      "--- 15000 - DyN Loss: 0.8706965446472168 - Max Loss: 4.39426851 - Mean Loss: 0.74406669 - Time: 23:31:10.191984\n",
      "tensor(0.0217, grad_fn=<DivBackward0>)\n",
      "--- 20000 - DyN Loss: 0.8403550982475281 - Max Loss: 4.47598696 - Mean Loss: 0.73072825 - Time: 23:37:00.727550\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hg/b92hf0r56hb4mrb3y64dq0400000gn/T/ipykernel_88102/579882364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mDyMat_optim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDyMat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mDyMat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_DyN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDyMat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDyMat_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dynEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanL_thres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeanL_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdyn_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_vec\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mDyMat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hg/b92hf0r56hb4mrb3y64dq0400000gn/T/ipykernel_88102/320482883.py\u001b[0m in \u001b[0;36mupdate_DyN\u001b[0;34m(_model, _optim, tar_Wio, dyn_epochs, meanL_thres)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_stress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_Wio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0m_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss_W\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0m_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_ep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdyn_epochs\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# q_dim, H_num = [5,5] means that we need 5*5*(500+500)=25000=0.1*500*500\n",
    "# one-tenth the parameters of the original matrix.\n",
    "for q_dim, H_num in [[5,5]]:\n",
    "    print('------')\n",
    "    configs = {\n",
    "        'H_num': H_num,\n",
    "        'q_dim': q_dim,\n",
    "        'norm_p': 1,\n",
    "        '_scale': 1\n",
    "    }\n",
    "\n",
    "    print(configs)\n",
    "    \n",
    "    DyMat_model = dynMat(num_rowQ, num_colQ, configs['H_num'], configs['q_dim'], p=configs['norm_p'], _scale=configs['_scale'])\n",
    "    DyMat_optim = torch.optim.Adam(DyMat_model.parameters(), lr=1e-4)\n",
    "\n",
    "    DyMat_model, _max, _mean = update_DyN(DyMat_model, DyMat_optim, tar_mat, max_dynEpoch, meanL_thres=meanL_thres)\n",
    "\n",
    "    dyn_vecs = rand_vec@DyMat_model.forward(_prec=-1)\n",
    "    res_norms = torch.norm(tar_vecs-dyn_vecs, dim=1)\n",
    "    norm_loss = torch.sum(res_norms)/(dyn_vecs.shape[0]*dyn_vecs.shape[1])\n",
    "    print(norm_loss/torch.std(tar_vecs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75797e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0217, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dyn_vecs = rand_vec@DyMat_model.forward(_prec=-1)\n",
    "res_norms = torch.norm(tar_vecs-dyn_vecs, dim=1)\n",
    "norm_loss = torch.sum(res_norms)/(dyn_vecs.shape[0]*dyn_vecs.shape[1])\n",
    "print(norm_loss/torch.std(tar_vecs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9320e59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a53e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a80adfeb",
   "metadata": {},
   "source": [
    "\n",
    "Feedforward an FC layer if the weights can be represented by a single distance matrix.\n",
    "There will be many warm-up procedures in a general CPU, so the speed improvement will be insignificant for a smaller matrix (e.g., dim < 1e+4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd650d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(X):\n",
    "    return np.argsort(X, axis=0), np.argsort(np.argsort(X, axis=0), axis=0)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def inner_loop(X,order,B,C,n,d,r_dim):\n",
    "    z = np.zeros(r_dim)\n",
    "    for k in range(r_dim):\n",
    "        for i in range(d):\n",
    "            q = order[k, i]\n",
    "            z[k] += X[k,i]*(2*C[q,i] - C[n-1,i]) + B[n-1,i] - 2*B[q,i]\n",
    "    return z\n",
    "\n",
    "def query(X, order1, order2, y, r_dim):\n",
    "    n,d = X.shape\n",
    "    B = np.take_along_axis((((X.T)*y)[:r_dim].T), order1, axis=0).cumsum(axis=0)\n",
    "    C = (y[order1.T][:r_dim].T).cumsum(axis=0)\n",
    "    res = inner_loop(X,order2,B,C,n,d,r_dim)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3793fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32768, 3) (36864, 3) (69632, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r_dim, c_dim, q_dim = 1024*32, 1024*36, 3\n",
    "\n",
    "query_vec = np.random.randn(c_dim)\n",
    "\n",
    "Row_coords = np.random.randn(r_dim, q_dim)\n",
    "Col_coords = np.random.randn(c_dim, q_dim)\n",
    "\n",
    "RC_coords = np.concatenate((Row_coords, Col_coords), axis=0)\n",
    "\n",
    "print(Row_coords.shape, Col_coords.shape, RC_coords.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "649d6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC: 45.93584108352661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32768, 36864)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Naive Method: Obtain the weights via computing the distance matrice with L1-norm\n",
    "ss = time.time()\n",
    "FC_weights = distance_matrix(Row_coords, Col_coords, p=1)#.astype(np.float32)    \n",
    "ee = time.time()\n",
    "print('TC:', ee-ss)\n",
    "FC_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ef4f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4056999683380127, 0.5634472370147705, 0.6175868511199951, 0.5821371078491211, 0.5890731811523438, 0.5718629360198975, 0.5798320770263672, 0.5889270305633545, 0.5879559516906738, 0.5862200260162354, 0.547415018081665]\n",
      "Average Time Cost: 0.5814457416534424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([327.02502683, 341.96596203, 360.42816509, 198.03636183,\n",
       "       167.27976265, 432.80154072, 683.53682971, 706.63540331,\n",
       "       376.82721384, 404.68833259])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Naive Method: Compute the matrix-vector multiplication\n",
    "naiveT_list = []\n",
    "for _ in range(11):\n",
    "    ss = time.time()\n",
    "    naive_output = FC_weights@query_vec\n",
    "    ee = time.time()\n",
    "    naiveT_list.append(ee-ss)\n",
    "    \n",
    "print(naiveT_list)\n",
    "print('Average Time Cost:', sum(naiveT_list[1:])/10)\n",
    "naive_output[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f6e1979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005308866500854492, 0.0060770511627197266, 0.0044858455657958984, 0.005629777908325195, 0.004824161529541016, 0.00467681884765625, 0.004562854766845703, 0.004745006561279297, 0.005925178527832031, 0.0048139095306396484, 0.005073070526123047]\n",
      "Average Time Cost: 0.005081367492675781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([327.02502683, 341.96596203, 360.42816509, 198.03636183,\n",
       "       167.27976265, 432.80154072, 683.53682971, 706.63540331,\n",
       "       376.82721384, 404.68833259])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Faster Method: Feedforward the FC layer using the sub-models' states directly without computing the distance matrix.\n",
    "RC_order1, RC_order2 = preprocess(RC_coords)\n",
    "\n",
    "exp_query_vec = np.zeros(r_dim + c_dim)\n",
    "exp_query_vec[-c_dim:] = query_vec\n",
    "\n",
    "fastT_list = []\n",
    "for i in range(11):\n",
    "    ss = time.time()\n",
    "    fast_output = query(RC_coords, RC_order1, RC_order2, exp_query_vec, r_dim)\n",
    "    ee = time.time()\n",
    "    fastT_list.append(ee-ss)\n",
    "    \n",
    "print(fastT_list)\n",
    "print('Average Time Cost:', sum(fastT_list[1:])/10)\n",
    "fast_output[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a6184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cac9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68966f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b75ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
