{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "356b8410",
   "metadata": {},
   "source": [
    "\n",
    "This notebook is used to present a toy trainer for an LeNet+DyN model.\n",
    "The complete training procedure involves multiple buffer mechanisms for permutating Dyn settings on the dev set.\n",
    "This procedure will be presented as an online open-sourced architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37287a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "# check device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b65639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "IMG_SIZE = 32\n",
    "N_CLASSES = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91ab439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define transforms\n",
    "data_transforms = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "# download and create datasets\n",
    "train_dataset = datasets.MNIST(root='datasets/MNIST', \n",
    "                               train=True, \n",
    "                               transform=data_transforms,\n",
    "                               download=True)\n",
    "\n",
    "valid_dataset = datasets.MNIST(root='datasets/MNIST', \n",
    "                               train=False, \n",
    "                               transform=data_transforms)\n",
    "\n",
    "# define the data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928c5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    '''\n",
    "    Function for the training step of the training loop\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "    \n",
    "        # Forward pass\n",
    "        y_hat, _ = model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    '''\n",
    "    Function for the validation step of the training loop\n",
    "    '''\n",
    "   \n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in valid_loader:\n",
    "    \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # Forward pass and record loss\n",
    "        y_hat, _ = model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "        \n",
    "    return model, epoch_loss\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            _, y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n\n",
    "\n",
    "\n",
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
    "    '''\n",
    "    Function defining the entire training loop\n",
    "    '''\n",
    "    #global c_dyn_model\n",
    "    # set objects for storing metrics\n",
    "    best_val = 0\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    " \n",
    "    # Train model\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            \n",
    "            train_acc = get_accuracy(model, train_loader, device=device)\n",
    "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "                \n",
    "#             print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "#                   f'Epoch: {epoch}\\t'\n",
    "#                   f'Train loss: {train_loss:.4f}\\t'\n",
    "#                   f'Valid loss: {valid_loss:.4f}\\t'\n",
    "#                   f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "#                   f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "    \n",
    "    return model, optimizer, (train_losses, valid_losses)\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        return out, probs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22a1d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_stress(dyn_model, c_model):\n",
    "\n",
    "    FT_convs, rec_CF0, rec_CF1, rec_CF2 = dyn_model.forward(c_model)\n",
    "    \n",
    "    loss_W = torch.sum(((rec_CF0-c_model.state_dict()['fc.weight'])**2)/rec_CF0.numel())\n",
    "    loss_W += torch.sum(((rec_CF1-c_model.state_dict()['fc1.weight'])**2)/rec_CF1.numel())\n",
    "    loss_W += torch.sum(((rec_CF2-c_model.state_dict()['fc2.weight'])**2)/rec_CF2.numel())\n",
    "    \n",
    "    for row_id in range(5):\n",
    "        for col_id in range(5):\n",
    "            loss_W += torch.sum(((FT_convs[row_id*5+col_id]-c_model.state_dict()['layer2.0.weight'][:,:,row_id,col_id])**2)/(16*6))\n",
    "\n",
    "    return loss_W\n",
    "\n",
    "\n",
    "def update_DyNs(dyn_model, c_model, _optim, dyn_epochs, loss_thres=0.1):\n",
    "\n",
    "    global c_dyn_model, cur_best_val\n",
    "    raw_valAcc = get_accuracy(c_model, valid_loader, device=DEVICE)\n",
    "    \n",
    "    for _ep in range(dyn_epochs):\n",
    "        loss_W = compute_stress(dyn_model, c_model)\n",
    "        _optim.zero_grad()\n",
    "        loss_W.backward()\n",
    "        _optim.step()\n",
    "        if loss_W.item() < loss_thres: return dyn_model, _ep, loss_W.item()\n",
    "            \n",
    "        if _ep %(dyn_epochs//10)==0:\n",
    "            rec_model = recover_LeNet(dyn_model, c_model, _prec=prec_id*1e-4)\n",
    "            valid_acc = get_accuracy(rec_model, valid_loader, device=DEVICE)\n",
    "            if valid_acc.item() > cur_best_val:\n",
    "                cur_best_val = valid_acc.item()\n",
    "                c_dyn_model = copy.deepcopy(dyn_model)\n",
    "            print(datetime.now().time().replace(microsecond=0), _ep, loss_W.item(), valid_acc.item())\n",
    "            if valid_acc > raw_valAcc: return dyn_model, _ep, loss_W.item()\n",
    "\n",
    "    return dyn_model, _ep, loss_W.item()\n",
    "\n",
    "\n",
    "def path_integral(dyn_model, _prec=0):\n",
    "        \n",
    "        FT_convs = []\n",
    "        _scale = dyn_model._scale\n",
    "        \n",
    "        for row_id in range(5):\n",
    "            for col_id in range(5):\n",
    "                inFT_Qs = dyn_model.inFT_Qs[row_id]\n",
    "                ouFT_Qs = dyn_model.ouFT_Qs[col_id]\n",
    "                \n",
    "                if _prec != 0:\n",
    "                    inFT_Qs = _prec*(torch.div(inFT_Qs, _prec, rounding_mode='floor'))\n",
    "                    ouFT_Qs = _prec*(torch.div(ouFT_Qs, _prec, rounding_mode='floor'))\n",
    "                \n",
    "                lambdas_FT = dyn_model.lambdas_FT[row_id*5+col_id]\n",
    "                \n",
    "                FT_convs.append(torch.sum((_scale/(torch.cdist(inFT_Qs, ouFT_Qs)))*lambdas_FT, 0))\n",
    "            \n",
    "        lambdas_ih1CF = dyn_model.lambdas_ih1CF\n",
    "        lambdas_h12CF = dyn_model.lambdas_h12CF\n",
    "        lambdas_h2oCF = dyn_model.lambdas_h2oCF\n",
    "        \n",
    "        inCF_Qs = dyn_model.inCF_Qs\n",
    "        h1CF_Qs = dyn_model.h1CF_Qs\n",
    "        h2CF_Qs = dyn_model.h2CF_Qs\n",
    "        ouCF_Qs = dyn_model.ouCF_Qs\n",
    "        \n",
    "        if _prec != 0:            \n",
    "            inCF_Qs = _prec*(torch.div(inCF_Qs, _prec, rounding_mode='floor'))\n",
    "            h1CF_Qs = _prec*(torch.div(h1CF_Qs, _prec, rounding_mode='floor'))\n",
    "            h2CF_Qs = _prec*(torch.div(h2CF_Qs, _prec, rounding_mode='floor'))\n",
    "            ouCF_Qs = _prec*(torch.div(ouCF_Qs, _prec, rounding_mode='floor'))\n",
    "            \n",
    "        rec_CF0 = torch.sum((_scale/(torch.cdist(h1CF_Qs, inCF_Qs)))*lambdas_ih1CF, 0)\n",
    "        rec_CF1 = torch.sum((_scale/(torch.cdist(h2CF_Qs, h1CF_Qs)))*lambdas_h12CF, 0)\n",
    "        rec_CF2 = torch.sum((_scale/(torch.cdist(ouCF_Qs, h2CF_Qs)))*lambdas_h2oCF, 0)\n",
    "\n",
    "        return FT_convs, rec_CF0, rec_CF1, rec_CF2\n",
    "\n",
    "\n",
    "\n",
    "def recover_LeNet(dyn_model, _model, _prec=0):\n",
    "    \n",
    "    c_model = copy.deepcopy(_model)\n",
    "    FT_convs, rec_CF0, rec_CF1, rec_CF2 = path_integral(dyn_model, _prec=_prec)\n",
    "    \n",
    "    c_model.state_dict()['fc.weight'].copy_(rec_CF0)\n",
    "    c_model.state_dict()['fc1.weight'].copy_(rec_CF1)\n",
    "    c_model.state_dict()['fc2.weight'].copy_(rec_CF2)\n",
    "    \n",
    "    for row_id in range(5):\n",
    "        for col_id in range(5):\n",
    "            conv_param = FT_convs[row_id*5+col_id]\n",
    "            c_model.state_dict()['layer2.0.weight'][:,:,row_id,col_id].copy_(conv_param)\n",
    "    \n",
    "    return c_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66ae54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class leNetDyNMat(nn.Module):\n",
    "    def __init__(self, num_ftQs, num_cfQs, q_dim, _scale):\n",
    "        super(leNetDyNMat, self).__init__() \n",
    "\n",
    "        self.q_dim = q_dim\n",
    "        \n",
    "        self.inFT_Qs = nn.Parameter(torch.rand(5, num_ftQs, 16, q_dim, device=DEVICE))\n",
    "        self.ouFT_Qs = nn.Parameter(torch.rand(5, num_ftQs, 6, q_dim, device=DEVICE))\n",
    "        \n",
    "        self.lambdas_FT = nn.Parameter(torch.randn(25, num_ftQs, 1, 1, device=DEVICE))\n",
    "        \n",
    "        self.inCF_Qs = nn.Parameter(torch.rand(num_cfQs, 400, q_dim, device=DEVICE))\n",
    "        self.h1CF_Qs = nn.Parameter(torch.rand(num_cfQs, 120, q_dim, device=DEVICE))\n",
    "        self.h2CF_Qs = nn.Parameter(torch.rand(num_cfQs, 84, q_dim, device=DEVICE))\n",
    "        self.ouCF_Qs = nn.Parameter(torch.rand(num_cfQs, 10, q_dim, device=DEVICE))\n",
    "        \n",
    "        self.lambdas_ih1CF = nn.Parameter(torch.randn(num_cfQs, 1, 1, device=DEVICE))\n",
    "        self.lambdas_h12CF = nn.Parameter(torch.randn(num_cfQs, 1, 1, device=DEVICE))\n",
    "        self.lambdas_h2oCF = nn.Parameter(torch.randn(num_cfQs, 1, 1, device=DEVICE))\n",
    "        \n",
    "        self._scale = _scale\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.raw_numParams = 5*(16+6)*num_ftQs*q_dim + q_dim*num_cfQs*(400+120+84+10)+num_cfQs*3+150+5*6+5*16+120+84+10\n",
    "        self.com_numParams = 5*(16+6)*num_ftQs + num_cfQs*(400+120+84+10)+num_cfQs*3+150+5*6+5*16+120+84+10\n",
    "        \n",
    "    def forward(self, c_model):\n",
    "        \n",
    "        FT_convs = []\n",
    "        \n",
    "        for row_id in range(5):\n",
    "            for col_id in range(5):\n",
    "                FT_convs.append(torch.sum((self._scale/(torch.cdist(self.inFT_Qs[row_id], self.ouFT_Qs[col_id])))\\\n",
    "                          *self.lambdas_FT[row_id*5+col_id], 0))\n",
    "                \n",
    "        rec_CF0 = torch.sum((self._scale/(torch.cdist(self.h1CF_Qs, self.inCF_Qs)))*self.lambdas_ih1CF, 0)\n",
    "        rec_CF1 = torch.sum((self._scale/(torch.cdist(self.h2CF_Qs, self.h1CF_Qs)))*self.lambdas_h12CF, 0)\n",
    "        rec_CF2 = torch.sum((self._scale/(torch.cdist(self.ouCF_Qs, self.h2CF_Qs)))*self.lambdas_h2oCF, 0)\n",
    "\n",
    "        return FT_convs, rec_CF0, rec_CF1, rec_CF2\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf6d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc2e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buffer_model = LeNet5(N_CLASSES).to(DEVICE)\n",
    "buffer_optim = torch.optim.Adam(buffer_model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa86ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dyn_model = leNetDyNMat(4,3,9,2)\n",
    "dyn_optim = torch.optim.Adam(dyn_model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9787b70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:37:53 0 501.8808898925781 0.09749999642372131\n",
      "17:37:57 200 127.29206085205078 0.07670000195503235\n",
      "17:38:00 400 56.02415466308594 0.07840000092983246\n",
      "17:38:04 600 30.76397705078125 0.11010000109672546\n",
      "17:38:07 800 18.857959747314453 0.12189999967813492\n",
      "17:38:11 1000 11.801366806030273 0.13179999589920044\n",
      "17:38:15 1200 6.245660781860352 0.10740000009536743\n",
      "17:38:18 1400 2.774937152862549 0.08470000326633453\n",
      "17:38:22 1600 1.1539548635482788 0.08839999884366989\n",
      "17:38:26 1800 0.5317487716674805 0.10409999638795853\n",
      "0 0.10010000318288803 --- Best ValAcc: 0.13179999589920044 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:39:00 0 0.07143969088792801 0.10100000351667404\n",
      "17:39:04 200 0.05131681263446808 0.40560001134872437\n",
      "17:39:07 400 0.046170923858881 0.6087999939918518\n",
      "17:39:11 600 0.04262854903936386 0.6560999751091003\n",
      "17:39:15 800 0.03984040394425392 0.698199987411499\n",
      "17:39:19 1000 0.0375080369412899 0.7487000226974487\n",
      "17:39:22 1200 0.035486627370119095 0.7567999958992004\n",
      "17:39:26 1400 0.033693306148052216 0.8112000226974487\n",
      "17:39:30 1600 0.0320754274725914 0.8349000215530396\n",
      "17:39:33 1800 0.030595704913139343 0.8550000190734863\n",
      "1 0.8755000233650208 --- Best ValAcc: 0.8550000190734863 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:40:08 0 0.03551807254552841 0.7578999996185303\n",
      "17:40:11 200 0.023418953642249107 0.9347000122070312\n",
      "17:40:15 400 0.02072111703455448 0.9502999782562256\n",
      "17:40:19 600 0.01887241192162037 0.9611999988555908\n",
      "17:40:23 800 0.01742321252822876 0.9674000144004822\n",
      "17:40:26 1000 0.01621021144092083 0.9718999862670898\n",
      "17:40:30 1200 0.015156524255871773 0.9743000268936157\n",
      "17:40:34 1400 0.014219875447452068 0.975600004196167\n",
      "17:40:38 1600 0.013374150730669498 0.9772999882698059\n",
      "17:40:41 1800 0.012601678259670734 0.9778000116348267\n",
      "2 0.9785000085830688 --- Best ValAcc: 0.9778000116348267 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:41:16 0 0.02146494947373867 0.9797000288963318\n",
      "17:41:19 200 0.011617839336395264 0.9850999712944031\n",
      "17:41:23 400 0.009851140901446342 0.9853000044822693\n",
      "17:41:27 600 0.008751209825277328 0.9848999977111816\n",
      "17:41:31 800 0.007945314049720764 0.9854000210762024\n",
      "17:41:35 1000 0.007303218822926283 0.9854000210762024\n",
      "17:41:38 1200 0.006763405632227659 0.9851999878883362\n",
      "17:41:42 1400 0.006292697507888079 0.9853000044822693\n",
      "17:41:46 1600 0.0058720349334180355 0.9858999848365784\n",
      "17:41:50 1800 0.005489435978233814 0.9868000149726868\n",
      "3 0.9865000247955322 --- Best ValAcc: 0.9868000149726868 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:42:30 0 0.01828477904200554 0.9865000247955322\n",
      "17:42:34 200 0.007884169928729534 0.9883000254631042\n",
      "17:42:38 400 0.006345714442431927 0.9884999990463257\n",
      "17:42:43 600 0.005415621213614941 0.9886000156402588\n",
      "17:42:47 800 0.004738384857773781 0.9883999824523926\n",
      "17:42:51 1000 0.004204952623695135 0.9883999824523926\n",
      "17:42:56 1200 0.003765566973015666 0.9883000254631042\n",
      "17:43:00 1400 0.0033935829997062683 0.9886999726295471\n",
      "17:43:04 1600 0.0030735002364963293 0.9889000058174133\n",
      "17:43:08 1800 0.0027918119449168444 0.9884999990463257\n",
      "4 0.9884999990463257 --- Best ValAcc: 0.9889000058174133 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:43:44 0 0.01607736013829708 0.9886000156402588\n",
      "17:43:48 200 0.004360473249107599 0.9884999990463257\n",
      "17:43:52 400 0.00326294032856822 0.9889000058174133\n",
      "17:43:56 600 0.002658847952261567 0.9887999892234802\n",
      "17:44:00 800 0.0022533724550157785 0.9891999959945679\n",
      "17:44:04 1000 0.001955413958057761 0.9894000291824341\n",
      "17:44:08 1200 0.0017243246547877789 0.9894000291824341\n",
      "17:44:12 1400 0.0015386604936793447 0.9891999959945679\n",
      "17:44:16 1600 0.0013934820890426636 0.9890999794006348\n",
      "17:44:20 1800 0.0012590863043442369 0.989300012588501\n",
      "5 0.9891999959945679 --- Best ValAcc: 0.9894000291824341 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:44:56 0 0.017031429335474968 0.9886000156402588\n",
      "6 0.9886000156402588 --- Best ValAcc: 0.9894000291824341 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:45:30 0 0.017700571566820145 0.9839000105857849\n",
      "17:45:34 200 0.0029659890569746494 0.9866999983787537\n",
      "17:45:39 400 0.0020058287773281336 0.9865000247955322\n",
      "17:45:43 600 0.0015581182669848204 0.9861000180244446\n",
      "17:45:47 800 0.0012946579372510314 0.9860000014305115\n",
      "17:45:51 1000 0.0011222722241654992 0.9861999750137329\n",
      "17:45:56 1200 0.0010034098522737622 0.9864000082015991\n",
      "17:46:00 1400 0.0009475038968957961 0.9860000014305115\n",
      "17:46:04 1600 0.0008512623026035726 0.9861000180244446\n",
      "17:46:08 1800 0.0008020576788112521 0.9865999817848206\n",
      "7 0.9865999817848206 --- Best ValAcc: 0.9894000291824341 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:46:46 0 0.016360387206077576 0.9876999855041504\n",
      "17:46:50 200 0.0015489037614315748 0.9897000193595886\n",
      "17:46:54 400 0.0010471094865351915 0.9896000027656555\n",
      "17:46:58 600 0.0008574706735089421 0.989799976348877\n",
      "17:47:02 800 0.0007641010452061892 0.9896000027656555\n",
      "17:47:06 1000 0.0007108192658051848 0.9894999861717224\n",
      "17:47:10 1200 0.0006772686028853059 0.9894999861717224\n",
      "17:47:13 1400 0.0006579255568794906 0.9894999861717224\n",
      "17:47:17 1600 0.0006459422293119133 0.9891999959945679\n",
      "17:47:21 1800 0.0006383651052601635 0.9894999861717224\n",
      "8 0.9894000291824341 --- Best ValAcc: 0.989799976348877 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:47:58 0 0.017955118790268898 0.9900000095367432\n",
      "9 0.9900000095367432 --- Best ValAcc: 0.9900000095367432 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:48:33 0 0.016707593575119972 0.9902999997138977\n",
      "10 0.9902999997138977 --- Best ValAcc: 0.9902999997138977 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:49:07 0 0.015968194231390953 0.9900000095367432\n",
      "17:49:11 200 0.0010450773406773806 0.9918000102043152\n",
      "11 0.9918000102043152 --- Best ValAcc: 0.9918000102043152 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:49:44 0 0.017624422907829285 0.9900000095367432\n",
      "17:49:48 200 0.001162807340733707 0.9908000230789185\n",
      "12 0.9908000230789185 --- Best ValAcc: 0.9918000102043152 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:50:22 0 0.01779433712363243 0.9922999739646912\n",
      "13 0.9922999739646912 --- Best ValAcc: 0.9922999739646912 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:50:57 0 0.01590690203011036 0.991599977016449\n",
      "14 0.991599977016449 --- Best ValAcc: 0.9922999739646912 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:51:31 0 0.01651988923549652 0.9912999868392944\n",
      "17:51:35 200 0.00115967879537493 0.9918000102043152\n",
      "17:51:39 400 0.0009395945235155523 0.991599977016449\n",
      "17:51:43 600 0.0008930108742788434 0.991599977016449\n",
      "17:51:46 800 0.0008591352379880846 0.9918000102043152\n",
      "17:51:50 1000 0.0008498012903146446 0.991599977016449\n",
      "17:51:54 1200 0.0008445940911769867 0.9922000169754028\n",
      "17:51:58 1400 0.0008420617668889463 0.9921000003814697\n",
      "17:52:02 1600 0.0008397190249525011 0.9919999837875366\n",
      "17:52:06 1800 0.000838201493024826 0.9919999837875366\n",
      "15 0.9921000003814697 --- Best ValAcc: 0.9922999739646912 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:52:43 0 0.01942840963602066 0.9919000267982483\n",
      "16 0.9919000267982483 --- Best ValAcc: 0.9922999739646912 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:53:17 0 0.017807738855481148 0.9915000200271606\n",
      "17 0.9915000200271606 --- Best ValAcc: 0.9922999739646912 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:53:51 0 0.01898708939552307 0.9897000193595886\n",
      "17:53:55 200 0.0010153177427127957 0.9890999794006348\n",
      "17:53:59 400 0.0008487679297104478 0.9894000291824341\n",
      "17:54:03 600 0.0008143309969455004 0.9894000291824341\n",
      "17:54:07 800 0.0008034404600039124 0.9891999959945679\n",
      "17:54:11 1000 0.0007988811121322215 0.9891999959945679\n",
      "17:54:15 1200 0.0008090457995422184 0.9894000291824341\n",
      "17:54:19 1400 0.0007948498823679984 0.9894999861717224\n",
      "17:54:23 1600 0.0008119485573843122 0.9890999794006348\n",
      "17:54:27 1800 0.0007928349077701569 0.9891999959945679\n",
      "18 0.9894000291824341 --- Best ValAcc: 0.9922999739646912 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n",
      "17:55:04 0 0.021171284839510918 0.9908999800682068\n",
      "19 0.9908999800682068 --- Best ValAcc: 0.9922999739646912 --- Raw NumParams: 21021 --- Compressed NumParams: 2765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c_dyn_model = leNetDyNMat(4,3,9,2)\n",
    "cur_best_val = 0\n",
    "prec_id = 10\n",
    "NN_update_epochs = 1\n",
    "DyN_update_epochs = 2000\n",
    "\n",
    "for dyn_batch in range(20):\n",
    "    buffer_model, optimizer, _ = training_loop(buffer_model, criterion, buffer_optim, \n",
    "                                               train_loader, valid_loader, NN_update_epochs, DEVICE)\n",
    "    \n",
    "    dyn_model, dyn_ep, dyn_loss = update_DyNs(dyn_model, buffer_model, dyn_optim, DyN_update_epochs, loss_thres=1e-5)\n",
    "    buffer_model = recover_LeNet(dyn_model, buffer_model, _prec=prec_id*1e-4)\n",
    "    buffer_optim = torch.optim.Adam(buffer_model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    valid_acc = get_accuracy(buffer_model, valid_loader, device=DEVICE)\n",
    "    \n",
    "    print(dyn_batch, valid_acc.item(), '--- Best ValAcc:', cur_best_val, '--- Raw NumParams:', dyn_model.raw_numParams, '--- Compressed NumParams:', dyn_model.com_numParams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219eac60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac19a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9922999739646912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "buffer_model = recover_LeNet(c_dyn_model, buffer_model, _prec=prec_id*1e-4)\n",
    "valid_acc = get_accuracy(buffer_model, valid_loader, device=DEVICE)\n",
    "print(valid_acc.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06503b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
